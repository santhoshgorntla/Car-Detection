{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077a771a",
   "metadata": {},
   "source": [
    "**Business Problem Statement\n",
    "\n",
    "How can we efficiently detect and track cars in video footage using computer vision techniques to improve road safety, optimize traffic monitoring, and enhance automated vehicle management systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b6ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a51f2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Read first frame\u001b[39;00m\n\u001b[0;32m     17\u001b[0m check, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread ()\n\u001b[1;32m---> 18\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor (frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Pass frame to our car classifier\u001b[39;00m\n\u001b[0;32m     21\u001b[0m cars \u001b[38;5;241m=\u001b[39m car_classifier\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray, \u001b[38;5;241m1.4\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Create our body classifier\n",
    "\n",
    "car_classifier = cv2. CascadeClassifier ('Haarcascades\\haarcascade_car.xml')\n",
    "\n",
    "# Initiate video capture for video file\n",
    "\n",
    "cap = cv2. VideoCapture('image_examples/cars.avi')\n",
    "\n",
    "# Loop once video is successfully Loaded\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    time.sleep(.05)\n",
    "    # Read first frame\n",
    "    check, frame = cap.read ()\n",
    "    gray = cv2.cvtColor (frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    #Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2. rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        cv2. imshow( 'Cars', frame)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4cef72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c076ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b1817f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
